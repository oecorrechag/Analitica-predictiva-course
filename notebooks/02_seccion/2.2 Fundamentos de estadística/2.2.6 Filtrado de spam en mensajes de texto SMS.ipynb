{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfc8fc6",
   "metadata": {},
   "source": [
    "# 2.2.6 Filtrado de spam en mensajes de texto SMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeefcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a715b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../../../\") \n",
    "\n",
    "from utils.paths import make_dir_line\n",
    "\n",
    "modality = 'u'\n",
    "project = 'Analitica predictiva'\n",
    "data = make_dir_line(modality, project)\n",
    "\n",
    "raw = data('raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88342a20",
   "metadata": {},
   "source": [
    "Los clasificadores Bayesianos ingenuos son herramientas de gran utilidad para la construcción de sistemas de clasificación, como ya se discutio en los tutoriales anteriores. En este tutorial se utiliza un clasificador Bayesiano ingenuo para determinar si un mensaje SMS es válido o es spam.\n",
    "\n",
    "## Definición del problema\n",
    "\n",
    "a recepción de publicidad no deseada a traves mensajes de texto usando SMS (Short Message Service) es un problema que afecta a muchos usuarios de teléfonos móviles. El problema radica en que los usuarios deben pagar por los mesajes recibidos, y por este motivo resulta muy importante que las compañías prestadoras del servicio puedan filtrar mensajes indeseados antes de enviarlos a su destinatario final. Los mensajes tienen una longitud máxima de 160 caracteres, por lo que el texto resulta poco para realizar la clasificación, en comparación con textos más largos (como los emails). Adicionalmente, los errores de digitación dificultan el proceso de detección automática.\n",
    "\n",
    "La muestra contiene 5574 mensajes en inglés, no codificados y clasificados como legítimos (ham) o spam (http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/). El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítico o spam, a partir del análisis de las palabras que contiente, partiendo del supuesto de que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje. Esto implica que en la fase de preparación de los datos se deben extraer las palabras que contiene cada mensaje para poder realizar el análsis.\n",
    "\n",
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    raw / \"sms-spam.csv\",\n",
    "    sep=\",\",\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f83884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Verifica la lectura de los datos\n",
    "#\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb812d",
   "metadata": {},
   "source": [
    "## Conteo de cantidad de mensajes por tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee954b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se obtiene la cantidad de casos para\n",
    "# cada tipo de mensaje.\n",
    "#\n",
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.type.value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se convierte el conteo anterior en probabilidades.\n",
    "#\n",
    "round(100 * df.type.value_counts() / sum(df.type.value_counts()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11914d",
   "metadata": {},
   "source": [
    "## Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se construye un stemmer que reduce una palabra a su raiz o 'stem'.\n",
    "# {llorar, lloramos, lloraron} -> llorar\n",
    "# {biblioteca, bibliotecario} -> bibliotec\n",
    "#\n",
    "stemmer = PorterStemmer()\n",
    "df[\"stemmed\"] = df.text.apply(lambda x: \" \".join([stemmer.stem(w) for w in x.split()]))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d7278",
   "metadata": {},
   "source": [
    "### Matriz de Términos del Documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c07ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Stopwords:\n",
    "#   i  me  my  myself  we  our  ours  ourselves ....\n",
    "#   am  is  are  was  were  be  been  being  have\n",
    "#   has  had  having  do  does  did  doing  ...\n",
    "#   a  an  the  and  but  if  or  because  as  until\n",
    "#   while  of  at  by  for  with  about  against ...\n",
    "#   ...\n",
    "#\n",
    "# token_pattern:\n",
    "# https://docs.python.org/3/howto/regex.html#regex-howto\n",
    "#\n",
    "#   \\w cualquier caracter alfanumerico [a-zA-Z0-9_]\n",
    "#   \\w\\w+ cadenas de dos o mas caracteres\n",
    "#   \\b  word boundary\n",
    "#\n",
    "count_vect = CountVectorizer(\n",
    "    analyzer=\"word\",                # a nivel de palabra\n",
    "    lowercase=True,                 # convierte a minúsculas\n",
    "    stop_words=\"english\",           # stop_words en inglés\n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b\", # patrones a reconocer\n",
    "    binary=True,                    # Los valores distintos de cero son fijados en 1\n",
    "    max_df=1.0,                     # máxima frecuencia a considerar\n",
    "    min_df=5,                       # ignora palabras con baja frecuencia\n",
    ")\n",
    "\n",
    "#\n",
    "# Aplica la función al texto\n",
    "#\n",
    "dtm = count_vect.fit_transform(df.stemmed)\n",
    "\n",
    "#\n",
    "# Las filas contienen los mensajes\n",
    "# y las clomunas los términos\n",
    "#\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Palabras aprendidas de los mensajes de texto\n",
    "#\n",
    "vocabulary = count_vect.get_feature_names_out()\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Primeras palabras del vocabulario\n",
    "#\n",
    "vocabulary[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd665a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se puede mejorar diciendo que solo se reconozcan\n",
    "# palabras formadas por letras\n",
    "#\n",
    "count_vect = CountVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    lowercase=True,\n",
    "    stop_words=\"english\",\n",
    "    token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\",\n",
    "    binary=True,\n",
    "    max_df=1.0,\n",
    "    min_df=5,\n",
    ")\n",
    "\n",
    "dtm = count_vect.fit_transform(df.stemmed)\n",
    "\n",
    "#\n",
    "# Las filas contienen los mensajes\n",
    "# y las clomunas los términos\n",
    "#\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25607ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = count_vect.get_feature_names_out()\n",
    "vocabulary[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1030f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Recupera los mensajes de la dtm\n",
    "#\n",
    "def dtm2words(dtm, vocabulary, index):\n",
    "    as_list = dtm[index, :].toarray().tolist()\n",
    "    docs = []\n",
    "    for i in index:\n",
    "        k = [vocabulary[iword] for iword, ifreq in enumerate(as_list[i]) if ifreq > 0]\n",
    "        docs += [k]\n",
    "    return docs\n",
    "\n",
    "\n",
    "for i, x in enumerate(dtm2words(dtm, vocabulary, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])):\n",
    "    print(\"Org: \", df.text[i])\n",
    "    print(\"Mod: \", \" \".join(x))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c5c1ce",
   "metadata": {},
   "source": [
    "### Conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58272265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Creación de los conjuntos de entrenamiento y prueba.\n",
    "#\n",
    "X_train = dtm[\n",
    "    0:4168,\n",
    "]\n",
    "X_test = dtm[\n",
    "    4169:,\n",
    "]\n",
    "\n",
    "y_train_true = df.type[0:4168]\n",
    "y_test_true = df.type[4169:]\n",
    "\n",
    "#\n",
    "# Distribución de los datos en el conjunto de entrenamiento.\n",
    "#\n",
    "round(100 * y_train_true.value_counts() / sum(y_train_true.value_counts()), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Distribución de los datos en el conjunto de entrenamiento.\n",
    "#\n",
    "round(100 * y_test_true.value_counts() / sum(y_test_true.value_counts()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f163fe",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se crea un clasificador Naive Bayes (NB)\n",
    "#\n",
    "clf = BernoulliNB()\n",
    "\n",
    "#\n",
    "# Se entrena el clasificador\n",
    "#\n",
    "clf.fit(X_train.toarray(), y_train_true)\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f630bc3",
   "metadata": {},
   "source": [
    "### Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se pronostica para los datos de prueba.\n",
    "#\n",
    "y_test_pred = clf.predict(X_test.toarray())\n",
    "y_test_pred_prob = clf.predict_proba(X_test.toarray())\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Métricas de desempeño\n",
    "#\n",
    "\n",
    "confusion_matrix(y_true=y_test_true, y_pred=y_test_pred)\n",
    "\n",
    "#\n",
    "# Pronostico en las columnas\n",
    "# Real en las filas\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543616b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Resulta más conveniente preparar una nueva tabla que\n",
    "# muestre la clasificación y no únicamente las\n",
    "# probabilidades.\n",
    "#\n",
    "results = pd.DataFrame(\n",
    "    data={\n",
    "        \"actual_type\": y_test_true,\n",
    "        \"predict_type\": y_test_pred,\n",
    "        \"prob_ham\": [v[0] for v in y_test_pred_prob],\n",
    "        \"prob_spam\": [v[1] for v in y_test_pred_prob],\n",
    "    }\n",
    ")\n",
    "\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Mensajes con clasificación errónea.\n",
    "# Resulta muy importante determinar porque los\n",
    "# mensajes están mal clasificados\n",
    "#\n",
    "results[results[\"actual_type\"] != results[\"predict_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27180329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Sin embargo, es mucho más intersante extraer\n",
    "# mensajes con probabilidades numéricamente\n",
    "# cercanas a 0.5. Estos podrían generar ambiguedad\n",
    "# en la clasificación.\n",
    "#\n",
    "results[(results[\"prob_spam\"] > 0.4) & (results[\"prob_spam\"] < 0.6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Mensajes mal clasificados con probabilidad cercana a 0.5\n",
    "#\n",
    "results[\n",
    "      (results[\"prob_spam\"] > 0.4)\n",
    "    & (results[\"prob_spam\"] < 0.6)\n",
    "    & (results[\"actual_type\"] != results[\"predict_type\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ok_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
