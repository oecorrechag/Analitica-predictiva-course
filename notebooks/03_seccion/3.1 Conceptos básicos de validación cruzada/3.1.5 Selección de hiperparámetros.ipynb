{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfc8fc6",
   "metadata": {},
   "source": [
    "# 3.1.5 Selección de hiperparámetros teniendo en cuenta la generalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b57b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb86f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb15a35",
   "metadata": {},
   "source": [
    "## 3.1.5.1 Definición del problema\n",
    "\n",
    "¿cómo seleccionar el grado del polinomio teniendo en cuenta que el error de generalización es una cantidad aleatoria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffa327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Función a aproximar\n",
    "# (Proceso geneador de datos)\n",
    "#\n",
    "def f(x):\n",
    "    return 2 * np.abs(np.sin(x * np.pi / 4 + 0.75)) / (1 + 0.1 * x)\n",
    "\n",
    "\n",
    "#\n",
    "# Datos reales.\n",
    "# (No disponibles en la realidad)\n",
    "#\n",
    "x_real = np.linspace(0, 10, 100)\n",
    "x_real = x_real[:, np.newaxis]\n",
    "y_real = f(x_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b66408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Muestra de datos.\n",
    "# (Información disponible en la realidad)\n",
    "#\n",
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "x_sample = np.linspace(0, 10, 100)\n",
    "rng.shuffle(x_sample)\n",
    "x_sample = x_sample[:25]\n",
    "x_sample = np.sort(x_sample)\n",
    "\n",
    "y_sample = f(x_sample)\n",
    "X_sample = x_sample[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se computa el promedio del SSE sobre 16 muestras\n",
    "#\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "n_samples = len(x_sample)\n",
    "n_test = 5\n",
    "n_train = n_samples - n_test\n",
    "\n",
    "degrees = list(range(1, 16))\n",
    "\n",
    "mse_train = []\n",
    "mse_test = []\n",
    "\n",
    "for i_degree, degree in enumerate(degrees):\n",
    "\n",
    "    np.random.seed(12345)\n",
    "\n",
    "    mse_train_by_sample = []\n",
    "    mse_test_by_sample = []\n",
    "\n",
    "    for i_sample in range(17):\n",
    "\n",
    "        #\n",
    "        # Modelo\n",
    "        #\n",
    "        indexes = np.random.choice(\n",
    "            n_samples,\n",
    "            n_train,\n",
    "            replace=False,\n",
    "        )\n",
    "\n",
    "        X_sample_train = X_sample[indexes]\n",
    "        y_sample_train = y_sample[indexes]\n",
    "\n",
    "        X_sample_test = np.delete(X_sample, indexes)\n",
    "        X_sample_test = X_sample_test[:, np.newaxis]\n",
    "        y_sample_test = np.delete(y_sample, indexes)\n",
    "\n",
    "        model = make_pipeline(\n",
    "            PolynomialFeatures(degree, include_bias=False),\n",
    "            MinMaxScaler(),\n",
    "            LinearRegression(),\n",
    "        )\n",
    "        model.fit(X_sample_train, y_sample_train)\n",
    "\n",
    "        y_pred_train = model.predict(X_sample_train)\n",
    "        y_pred_test = model.predict(X_sample_test)\n",
    "\n",
    "        mse_train_by_sample.append(mean_squared_error(y_sample_train, y_pred_train))\n",
    "        mse_test_by_sample.append(mean_squared_error(y_sample_test, y_pred_test))\n",
    "\n",
    "    mse_train.append(np.mean(mse_train_by_sample))\n",
    "    mse_test.append(np.mean(mse_test_by_sample))\n",
    "\n",
    "plt.plot(degrees, mse_train, color=\"tab:blue\", linewidth=2, label=\"fit\")\n",
    "plt.plot(degrees, mse_test, color=\"tab:orange\", linewidth=2, label=\"test\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.gca().spines[\"left\"].set_color(\"gray\")\n",
    "plt.gca().spines[\"bottom\"].set_color(\"gray\")\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 13))\n",
    "\n",
    "optimal_degree = 8\n",
    "\n",
    "n_samples = len(x_sample)\n",
    "n_test = 5\n",
    "n_train = n_samples - n_test\n",
    "\n",
    "for i_plot in range(16):\n",
    "\n",
    "    plt.subplot(4, 4, i_plot + 1)\n",
    "\n",
    "    #\n",
    "    # Datos\n",
    "    #\n",
    "    plt.plot(x_real, y_real, \"--\", color=\"black\", alpha=1.0, zorder=10)\n",
    "    plt.plot(x_sample, y_sample, \"o\", color=\"black\", alpha=1.0, zorder=10)\n",
    "\n",
    "    #\n",
    "    # Modelo\n",
    "    #\n",
    "    indexes = np.random.choice(\n",
    "        n_samples,\n",
    "        n_train,\n",
    "        replace=False,\n",
    "    )\n",
    "\n",
    "    X_sample_train = X_sample[indexes]\n",
    "    y_sample_train = y_sample[indexes]\n",
    "\n",
    "    X_sample_test = np.delete(X_sample, indexes)\n",
    "    y_sample_test = np.delete(y_sample, indexes)\n",
    "\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(optimal_degree),\n",
    "        MinMaxScaler(),\n",
    "        LinearRegression(),\n",
    "    )\n",
    "    model.fit(X_sample_train, y_sample_train)\n",
    "    y_predicted = model.predict(x_real)\n",
    "\n",
    "    plt.plot(x_real, y_predicted, color=\"tab:blue\", linewidth=3, zorder=2, alpha=0.8)\n",
    "\n",
    "    plt.plot(\n",
    "        X_sample_test,\n",
    "        y_sample_test,\n",
    "        \"o\",\n",
    "        color=\"black\",\n",
    "        fillstyle=\"none\",\n",
    "        markersize=11,\n",
    "    )\n",
    "\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    plt.gca().spines[\"left\"].set_color(\"gray\")\n",
    "    plt.gca().spines[\"bottom\"].set_color(\"gray\")\n",
    "    plt.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.gca().spines[\"right\"].set_visible(False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ok_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
