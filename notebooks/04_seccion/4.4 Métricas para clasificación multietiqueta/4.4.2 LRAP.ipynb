{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfc8fc6",
   "metadata": {},
   "source": [
    "# 4.4.2 Label ranking average precision (LRAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5faf99",
   "metadata": {},
   "source": [
    "Promedia sobre las muestras la respuesta a la siguiente pregunta: ¿para cada etiqueta verdadera, que fracción de etiquetas mejor rankeadas son etiquetas verdaderas?\n",
    "\n",
    "Se computa como:\n",
    "\n",
    "$$ LRAP(y, \\hat{y})  = \\frac{1}{n_{samples}} \\sum_{i=0}^{n_{samples}} \\frac{1}{||y_i||_{0}} \\sum_{j:y_{i,j} = 1}^{} \\frac{|L_{i,j}|}{rank_{i,j}} $$\n",
    "\n",
    "- $ L_{i,j} = \\{ k: y_{i,k} = 1, \\hat{f_{i,k}} >= \\hat{f_{i,j}} \\}$\n",
    "- $ rank_{i,j} = |{k: \\hat{f_{i,k}} >= \\hat{f_{i,j}}} | $\n",
    "- |.| es la cantidad de elementos del conjunto.\n",
    "- ||.||_{0} es el número de elementos diferentes de cero en un vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(\n",
    "    [\n",
    "        # A B  C\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "y_score = np.array(\n",
    "    [\n",
    "        #   A    B    C\n",
    "        [0.75, 0.5, 1.0],\n",
    "        [1.00, 0.2, 0.1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "#          1      1      1      1\n",
    "# 0.5 * [ --- * (---) + --- * (---) ] = 0.4166\n",
    "#          1      2      1      3\n",
    "#\n",
    "\n",
    "label_ranking_average_precision_score(\n",
    "    # -------------------------------------------------------------------------\n",
    "    # True binary labels in binary indicator format.\n",
    "    y_true=y_true,\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Target scores, can either be probability estimates of the positive class,\n",
    "    # confidence values, or non-thresholded measure of decisions\n",
    "    y_score=y_score,\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Sample weights.\n",
    "    sample_weight=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ok_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
