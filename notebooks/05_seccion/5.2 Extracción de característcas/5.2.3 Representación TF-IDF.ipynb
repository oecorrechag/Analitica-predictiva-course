{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bfc8fc6",
   "metadata": {},
   "source": [
    "# 5.2.3 Representación TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b57b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb86f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8513e901",
   "metadata": {},
   "source": [
    "En una matriz documento-término, las cantidades representan la ocurrencia de un token en cada uno de los documentos.\n",
    "\n",
    "Las palabras como artículos, verbos ser/estar, conectores, etc. son palabras muy comunes en los textos (tienen frecuencias altas en una matriz documento-término) y tienen poca utilidad para extraer información valiosa de un documento. Adicionalmente, distorcionan y obscurecen términos interesantes que serían de mucha más utilidad.\n",
    "\n",
    "La representación TF-IDF (term-frequency inverse document-frequency) recomputa los valores de la matriz como:\n",
    "\n",
    "$$ tf-idf(t,d) = tf(t,d) x idf(t) $$\n",
    "\n",
    "- $t$ representa el término.\n",
    "- $d$ representa el documento.\n",
    "\n",
    "La transformación también pondera la frecuencia de cada token respecto a su frecuencia en el documento y la cantidad de tokens en dicho documento.\n",
    "\n",
    "Para explicar esta representación considere la siguiente matriz documento-termino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0608f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1],\n",
       "       [2, 0, 0],\n",
       "       [3, 0, 0],\n",
       "       [4, 0, 0],\n",
       "       [3, 2, 0],\n",
       "       [3, 0, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# tf: term-frequency\n",
    "#\n",
    "tf = np.array(\n",
    "    [\n",
    "        [3, 0, 1],\n",
    "        [2, 0, 0],\n",
    "        [3, 0, 0],\n",
    "        [4, 0, 0],\n",
    "        [3, 2, 0],\n",
    "        [3, 0, 2],\n",
    "    ]\n",
    ")\n",
    "\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7274c840",
   "metadata": {},
   "source": [
    "Ahora se crea el transformador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8863a778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5883954 , 0.        , 0.4116046 ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.34950701, 0.65049299, 0.        ],\n",
       "       [0.41682734, 0.        , 0.58317266]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TfidfTransformer(\n",
    "    # -------------------------------------------------------------\n",
    "    # Each output row will have unit norm.\n",
    "    # \"l1\", \"l2\"\n",
    "    norm=\"l1\",\n",
    "    # -------------------------------------------------------------\n",
    "    # Enable inverse-document-frequency reweighting.\n",
    "    use_idf=True,\n",
    "    # -------------------------------------------------------------\n",
    "    # Smooth idf weights by adding one to document frequencies, as\n",
    "    # if an extra document was seen containing every term in the\n",
    "    # collection exactly once. Prevents zero divisions.\n",
    "    smooth_idf=False,\n",
    "    # -------------------------------------------------------------\n",
    "    # Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "    sublinear_tf=False,\n",
    ")\n",
    "\n",
    "transformer.fit_transform(tf).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7621177a",
   "metadata": {},
   "source": [
    "## 5.2.3.1 Caso 1\n",
    "\n",
    "* norm=\"l1\"\n",
    "\n",
    "* use_idf=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47cb4d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1],\n",
       "       [2, 0, 0],\n",
       "       [3, 0, 0],\n",
       "       [4, 0, 0],\n",
       "       [3, 2, 0],\n",
       "       [3, 0, 2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# term-frequency\n",
    "#\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ff2b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4, 4],\n",
       "       [2, 2, 2],\n",
       "       [3, 3, 3],\n",
       "       [4, 4, 4],\n",
       "       [5, 5, 5],\n",
       "       [5, 5, 5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# norma \"l1\" de cada fila\n",
    "#\n",
    "row_norm = np.tile(tf.sum(axis=1).reshape(-1, 1), (1, 3))\n",
    "row_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48d9958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75, 0.  , 0.25],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.6 , 0.4 , 0.  ],\n",
       "       [0.6 , 0.  , 0.4 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf / row_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f3d67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75, 0.  , 0.25],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.6 , 0.4 , 0.  ],\n",
       "       [0.6 , 0.  , 0.4 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Verificación\n",
    "#\n",
    "TfidfTransformer(\n",
    "    norm=\"l1\",\n",
    "    use_idf=False,\n",
    "    smooth_idf=False,\n",
    "    sublinear_tf=False,\n",
    ").fit_transform(tf).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7ab44",
   "metadata": {},
   "source": [
    "## 5.2.3.2 Caso 2\n",
    "\n",
    "* norm=\"l2\"\n",
    "\n",
    "* use_idf=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a1d2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1],\n",
       "       [2, 0, 0],\n",
       "       [3, 0, 0],\n",
       "       [4, 0, 0],\n",
       "       [3, 2, 0],\n",
       "       [3, 0, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# term-frequency\n",
    "#\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c52da47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.16227766, 3.16227766, 3.16227766],\n",
       "       [2.        , 2.        , 2.        ],\n",
       "       [3.        , 3.        , 3.        ],\n",
       "       [4.        , 4.        , 4.        ],\n",
       "       [3.60555128, 3.60555128, 3.60555128],\n",
       "       [3.60555128, 3.60555128, 3.60555128]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# norma \"l2\" de cada fila\n",
    "#\n",
    "row_norm = np.tile(np.sqrt(np.power(tf, 2).sum(axis=1).reshape(-1, 1)), (1, 3))\n",
    "row_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "508c1fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9486833 , 0.        , 0.31622777],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.83205029, 0.5547002 , 0.        ],\n",
       "       [0.83205029, 0.        , 0.5547002 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf / row_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27754a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9486833 , 0.        , 0.31622777],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.83205029, 0.5547002 , 0.        ],\n",
       "       [0.83205029, 0.        , 0.5547002 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Verificación\n",
    "#\n",
    "TfidfTransformer(\n",
    "    norm=\"l2\",\n",
    "    use_idf=False,\n",
    "    smooth_idf=False,\n",
    "    sublinear_tf=False,\n",
    ").fit_transform(tf).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04a60b",
   "metadata": {},
   "source": [
    "## 5.2.3.3 Caso 3\n",
    "\n",
    "* norm=\"l2\"\n",
    "\n",
    "* use_idf=True\n",
    "\n",
    "* smooth_idf=False\n",
    "\n",
    "* sublinear_tf=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1beba230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# número de documentos = 6\n",
    "#\n",
    "n = tf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18054a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Cuenta los documentos en que aparece un término\n",
    "#\n",
    "df = np.where(tf > 0, 1, 0)\n",
    "df = df.sum(axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "634a5a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 2.79175947, 2.09861229],\n",
       "       [1.        , 2.79175947, 2.09861229],\n",
       "       [1.        , 2.79175947, 2.09861229],\n",
       "       [1.        , 2.79175947, 2.09861229],\n",
       "       [1.        , 2.79175947, 2.09861229],\n",
       "       [1.        , 2.79175947, 2.09861229]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Computa idf(t). Para smooth_idf=False\n",
    "#\n",
    "#                  n\n",
    "#   idf(t) = log ---- + 1\n",
    "#                 df\n",
    "#\n",
    "idf = np.log(n / df) + 1\n",
    "idf = np.tile(idf, (6, 1))\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "face8521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.        , 0.        , 2.09861229],\n",
       "       [2.        , 0.        , 0.        ],\n",
       "       [3.        , 0.        , 0.        ],\n",
       "       [4.        , 0.        , 0.        ],\n",
       "       [3.        , 5.58351894, 0.        ],\n",
       "       [3.        , 0.        , 4.19722458]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_raw = tf * idf\n",
    "tf_idf_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bea2ec7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.66117106, 3.66117106, 3.66117106],\n",
       "       [2.        , 2.        , 2.        ],\n",
       "       [3.        , 3.        , 3.        ],\n",
       "       [4.        , 4.        , 4.        ],\n",
       "       [6.33842912, 6.33842912, 6.33842912],\n",
       "       [5.15913696, 5.15913696, 5.15913696]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_norm = np.tile(np.sqrt(np.power(tf_idf_raw, 2).sum(axis=1).reshape(-1, 1)), (1, 3))\n",
    "row_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ec04812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81940995, 0.        , 0.57320793],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.47330339, 0.88089948, 0.        ],\n",
       "       [0.58149261, 0.        , 0.81355169]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = tf_idf_raw / row_norm\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba98edd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81940995, 0.        , 0.57320793],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.47330339, 0.88089948, 0.        ],\n",
       "       [0.58149261, 0.        , 0.81355169]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Verificación\n",
    "#\n",
    "TfidfTransformer(\n",
    "    norm=\"l2\",\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    sublinear_tf=False,\n",
    ").fit_transform(tf).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c53ab",
   "metadata": {},
   "source": [
    "## 5.2.3.4 Caso 4\n",
    "\n",
    "* norm=\"l2\"\n",
    "\n",
    "* use_idf=True\n",
    "\n",
    "* smooth_idf=True\n",
    "\n",
    "* sublinear_tf=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd1def07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Computa idf(t). Para smooth_idf=True. Equivale\n",
    "# a un documento que tiene todos los terminos\n",
    "#\n",
    "#                  1+n\n",
    "#   idf(t) = log ------ + 1\n",
    "#                 1+df\n",
    "#\n",
    "idf = np.log((1 + n) / (1 + df)) + 1\n",
    "idf = np.tile(idf, (6, 1))\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d16f99de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.        , 0.        , 1.84729786],\n",
       "       [2.        , 0.        , 0.        ],\n",
       "       [3.        , 0.        , 0.        ],\n",
       "       [4.        , 0.        , 0.        ],\n",
       "       [3.        , 4.50552594, 0.        ],\n",
       "       [3.        , 0.        , 3.69459572]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_raw = tf * idf\n",
    "tf_idf_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bef880bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.52313914, 3.52313914, 3.52313914],\n",
       "       [2.        , 2.        , 2.        ],\n",
       "       [3.        , 3.        , 3.        ],\n",
       "       [4.        , 4.        , 4.        ],\n",
       "       [5.41292564, 5.41292564, 5.41292564],\n",
       "       [4.75920556, 4.75920556, 4.75920556]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_norm = np.tile(np.sqrt(np.power(tf_idf_raw, 2).sum(axis=1).reshape(-1, 1)), (1, 3))\n",
    "row_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0af6630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85151335, 0.        , 0.52433293],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.55422893, 0.83236428, 0.        ],\n",
       "       [0.63035731, 0.        , 0.77630514]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = tf_idf_raw / row_norm\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "552310c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85151335, 0.        , 0.52433293],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.55422893, 0.83236428, 0.        ],\n",
       "       [0.63035731, 0.        , 0.77630514]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Verificación\n",
    "#\n",
    "TfidfTransformer(\n",
    "    norm=\"l2\",\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=False,\n",
    ").fit_transform(tf).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12244b0e",
   "metadata": {},
   "source": [
    "## 5.2.3.5 Caso 5\n",
    "\n",
    "* norm=\"l2\"\n",
    "\n",
    "* use_idf=True\n",
    "\n",
    "* smooth_idf=True\n",
    "\n",
    "* sublinear_tf=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71eebf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786],\n",
       "       [1.        , 2.25276297, 1.84729786]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Computa idf(t). Para smooth_idf=True. Equivale\n",
    "# a un documento que tiene todos los terminos\n",
    "#\n",
    "#                  1+n\n",
    "#   idf(t) = log ------ + 1\n",
    "#                 1+df\n",
    "#\n",
    "idf = np.log((1 + n) / (1 + df)) + 1\n",
    "idf = np.tile(idf, (6, 1))\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70d1be99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.09861229, 0.        , 1.84729786],\n",
       "       [1.69314718, 0.        , 0.        ],\n",
       "       [2.09861229, 0.        , 0.        ],\n",
       "       [2.38629436, 0.        , 0.        ],\n",
       "       [2.09861229, 3.81425927, 0.        ],\n",
       "       [2.09861229, 0.        , 3.12774716]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Cuando sublinear_tf=True, reemplaza tf por 1 + log(tf)\n",
    "#\n",
    "mylog = lambda x: 1 + np.log(x) if x > 0 else 0\n",
    "\n",
    "tf_idf_raw = np.vectorize(mylog)(tf) * idf\n",
    "tf_idf_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e57ef5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.79583314, 2.79583314, 2.79583314],\n",
       "       [1.69314718, 1.69314718, 1.69314718],\n",
       "       [2.09861229, 2.09861229, 2.09861229],\n",
       "       [2.38629436, 2.38629436, 2.38629436],\n",
       "       [4.35347531, 4.35347531, 4.35347531],\n",
       "       [3.76656022, 3.76656022, 3.76656022]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_norm = np.tile(np.sqrt(np.power(tf_idf_raw, 2).sum(axis=1).reshape(-1, 1)), (1, 3))\n",
    "row_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2051eea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75062144, 0.        , 0.66073252],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.48205448, 0.87614124, 0.        ],\n",
       "       [0.55716945, 0.        , 0.83039882]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = tf_idf_raw / row_norm\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1058616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75062144, 0.        , 0.66073252],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.48205448, 0.87614124, 0.        ],\n",
       "       [0.55716945, 0.        , 0.83039882]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Verificación\n",
    "#\n",
    "TfidfTransformer(\n",
    "    norm=\"l2\",\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True,\n",
    ").fit_transform(tf).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f2f003d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok_\n"
     ]
    }
   ],
   "source": [
    "print('ok_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
