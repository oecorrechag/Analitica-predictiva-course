{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2.2 Método de Covarianza Reducida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "from sklearn.covariance import OAS, LedoitWolf, ShrunkCovariance, empirical_covariance, log_likelihood\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://youtu.be/x223K0ex1xk?si=6L96kNGHDUig4FhK\n",
    "\n",
    "Links: https://scikit-learn.org/stable/auto_examples/covariance/plot_covariance_estimation.html\n",
    "\n",
    "La covarianza empírica de una muestra de datos puede ser computada usando el método de máxima verosimilitud (EmpiricalCovariance), cuando hay un número suficiente de datos; sin embargo, la estimación es sensible a la presencia de outliers, y a otros muchos aspectos de los datos.\n",
    "\n",
    "Una estimación inapropiada (poco precisa) de la matriz de covarianzas causa que la matriz de precisión (la inversa de la matriz de covarianzas) no pueda ser estimada. Dicha matriz de precisión es una alternativa al uso de la matriz de covarianzas y se suele utilizar en muchas metodologías.\n",
    "\n",
    "Los métodos de covarianza reducida son una aproximación que mejora la aproximación de los valores propios de la matriz de covarianzas, logrando que su inversión sea más precisa, esto es, la computación de la matriz de precisión.\n",
    "\n",
    "La transformación aplicada es la siguiente:\n",
    "\n",
    "$$ \\sum_{shrunk}^{} = (1 − \\alpha) \\hat{\\Sigma} + \\alpha \\frac{Tr \\hat{\\Sigma}}{p} Id $$\n",
    "\n",
    "Ledoit & Wolf proponen un método para computar el valor óptimo de $\\alpha$ que minimiza el error cuadrático medio entre la matriz de covarianza real y la estimada.\n",
    "\n",
    "Chen et al proponen una formula alternativa que mejora el resultado de Ledoit & Wolf. Esta es conocida como Oracle Shrinkage Approximating estimator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Tamaño de las muestras\n",
    "#\n",
    "n_features, n_samples = 40, 20\n",
    "\n",
    "#\n",
    "# Generación de las muestras\n",
    "#\n",
    "np.random.seed(42)\n",
    "base_X_train = np.random.normal(size=(n_samples, n_features))\n",
    "base_X_test = np.random.normal(size=(n_samples, n_features))\n",
    "\n",
    "coloring_matrix = np.random.normal(size=(n_features, n_features))\n",
    "X_train = np.dot(base_X_train, coloring_matrix)\n",
    "X_test = np.dot(base_X_test, coloring_matrix)\n",
    "\n",
    "#\n",
    "# Cálculo de la covarianza real de los datos\n",
    "#\n",
    "real_cov = np.dot(coloring_matrix.T, coloring_matrix)\n",
    "emp_cov = empirical_covariance(X_train)\n",
    "loglik_real = -log_likelihood(emp_cov, linalg.inv(real_cov))\n",
    "\n",
    "#\n",
    "# Covarianza computada para la muestra de prueba usando\n",
    "# diferentes valores del coeficiente de regularización\n",
    "#\n",
    "shrinkages = np.logspace(-2, 0, 30)\n",
    "negative_logliks = [\n",
    "    -ShrunkCovariance(shrinkage=s).fit(X_train).score(X_test) for s in shrinkages\n",
    "]\n",
    "\n",
    "#\n",
    "# Búsqueda del mejor coeficiente de regularización usando\n",
    "# validación cruzada\n",
    "#\n",
    "tuned_parameters = [{\"shrinkage\": shrinkages}]\n",
    "cv = GridSearchCV(\n",
    "    ShrunkCovariance(),\n",
    "    tuned_parameters,\n",
    ")\n",
    "cv.fit(X_train)\n",
    "loglik_cv = cv.best_estimator_.score(X_test)\n",
    "\n",
    "\n",
    "#\n",
    "# Mejor coeficiente de regularización usando\n",
    "# Oracle Approximating Shrinkage\n",
    "#\n",
    "lw = LedoitWolf()\n",
    "loglik_lw = lw.fit(X_train).score(X_test)\n",
    "\n",
    "#\n",
    "# Mejor coeficiente de regularización usando el método\n",
    "# de Ledoit-Wolf\n",
    "#\n",
    "oas = OAS()\n",
    "loglik_oas = oas.fit(X_train).score(X_test)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.title(\"Regularized covariance: likelihood and shrinkage coefficient\")\n",
    "plt.xlabel(\"Regularization parameter: shrinkage coefficient\")\n",
    "plt.ylabel(\"Error: negative log-likelihood on test data\")\n",
    "\n",
    "\n",
    "plt.loglog(shrinkages, negative_logliks, label=\"Negative log-likelihood\")\n",
    "\n",
    "plt.plot(plt.xlim(), 2 * [loglik_real], \"--r\", label=\"Real covariance likelihood\")\n",
    "\n",
    "# adjust view\n",
    "lik_max = np.amax(negative_logliks)\n",
    "lik_min = np.amin(negative_logliks)\n",
    "ymin = lik_min - 6.0 * np.log((plt.ylim()[1] - plt.ylim()[0]))\n",
    "ymax = lik_max + 10.0 * np.log(lik_max - lik_min)\n",
    "xmin = shrinkages[0]\n",
    "xmax = shrinkages[-1]\n",
    "\n",
    "plt.vlines(\n",
    "    lw.shrinkage_,\n",
    "    ymin,\n",
    "    -loglik_lw,\n",
    "    color=\"magenta\",\n",
    "    linewidth=3,\n",
    "    label=\"Ledoit-Wolf estimate\",\n",
    ")\n",
    "\n",
    "plt.vlines(\n",
    "    oas.shrinkage_, ymin, -loglik_oas, color=\"purple\", linewidth=3, label=\"OAS estimate\"\n",
    ")\n",
    "\n",
    "plt.vlines(\n",
    "    cv.best_estimator_.shrinkage,\n",
    "    ymin,\n",
    "    -loglik_cv,\n",
    "    color=\"cyan\",\n",
    "    linewidth=3,\n",
    "    label=\"Cross-validation best estimate\",\n",
    ")\n",
    "\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok_\n"
     ]
    }
   ],
   "source": [
    "print('ok_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
